From 1168c676a526642219df06dcc60f652775097272 Mon Sep 17 00:00:00 2001
From: QYan <qyan_0131@tongji.edu.cn>
Date: Sat, 14 Dec 2024 22:37:05 +0800
Subject: [PATCH] MPLSeg

---
 configs/_base_/schedules/schedule_125k.py    |   9 ++
 configs/mplseg/mplseg_resnet18_cityscapes.py | 112 ++++++++++++++
 mmseg/models/backbones/__init__.py           |   4 +-
 mmseg/models/backbones/mplseg.py             | 148 +++++++++++++++++++
 mmseg/models/losses/__init__.py              |   4 +-
 mmseg/models/losses/psl_loss.py              |  78 ++++++++++
 6 files changed, 353 insertions(+), 2 deletions(-)
 create mode 100644 configs/_base_/schedules/schedule_125k.py
 create mode 100644 configs/mplseg/mplseg_resnet18_cityscapes.py
 create mode 100644 mmseg/models/backbones/mplseg.py
 create mode 100644 mmseg/models/losses/psl_loss.py

diff --git a/configs/_base_/schedules/schedule_125k.py b/configs/_base_/schedules/schedule_125k.py
new file mode 100644
index 00000000..037c9d33
--- /dev/null
+++ b/configs/_base_/schedules/schedule_125k.py
@@ -0,0 +1,9 @@
+# optimizer
+optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)
+optimizer_config = dict()
+# learning policy
+lr_config = dict(policy='poly', power=0.9, min_lr=1e-4, by_epoch=False)
+# runtime settings
+runner = dict(type='IterBasedRunner', max_iters=125000)
+checkpoint_config = dict(by_epoch=False, interval=12500)
+evaluation = dict(interval=12500, metric='mIoU', pre_eval=True)
diff --git a/configs/mplseg/mplseg_resnet18_cityscapes.py b/configs/mplseg/mplseg_resnet18_cityscapes.py
new file mode 100644
index 00000000..2a749e17
--- /dev/null
+++ b/configs/mplseg/mplseg_resnet18_cityscapes.py
@@ -0,0 +1,112 @@
+_base_ = [
+    '../_base_/datasets/cityscapes.py',
+    '../_base_/default_runtime.py', '../_base_/schedules/schedule_125k.py'
+]
+
+norm_cfg = dict(type='SyncBN', requires_grad=True)
+model = dict(
+    type='EncoderDecoder',
+    backbone=dict(
+        type='MPLSeg',
+        backbone_channels=(64, 128, 256, 512),
+        mid_channels=(256, 384, 512, 512),
+        fuse_channels=(128, 192, 256, 256),
+        out_indices=(0, 1, 2, 3),
+        backbone_cfg=dict(
+            type='ResNetV1c',
+            in_channels=3,
+            depth=18,
+            num_stages=4,
+            out_indices=(0, 1, 2, 3),
+            dilations=(1, 1, 1, 1),
+            strides=(1, 2, 2, 2),
+            norm_cfg=norm_cfg,
+            norm_eval=False,
+            style='pytorch',
+            contract_dilation=True,
+            init_cfg=dict(
+                type='Pretrained', checkpoint='open-mmlab://resnet18_v1c')),
+        norm_cfg=norm_cfg,
+        init_cfg=None),
+    decode_head=dict(
+        type='FCNHead',
+        in_channels=128,
+        in_index=0,
+        channels=64,
+        num_convs=1,
+        concat_input=False,
+        dropout_ratio=0.1,
+        num_classes=19,
+        norm_cfg=norm_cfg,
+        align_corners=False,
+        loss_decode=[
+            dict(type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
+            ]),
+    auxiliary_head=[
+dict(
+            type='FCNHead',
+            in_channels=192,
+            channels=64,
+            num_convs=1,
+            num_classes=19,
+            in_index=1,
+            norm_cfg=norm_cfg,
+            concat_input=False,
+            align_corners=False,
+            loss_decode=[
+                dict(
+                    type='CrossEntropyLoss',
+                    use_sigmoid=False,
+                    loss_weight=0.1),
+                dict(
+                type='PSLLoss', use_sigmoid=False, loss_weight=0.75)
+                ]),
+        dict(
+            type='FCNHead',
+            in_channels=256,
+            channels=64,
+            num_convs=1,
+            num_classes=19,
+            in_index=2,
+            norm_cfg=norm_cfg,
+            concat_input=False,
+            align_corners=False,
+            loss_decode=[
+                dict(
+                    type='CrossEntropyLoss',
+                    use_sigmoid=False,
+                    loss_weight=0.1),
+                dict(
+                type='PSLLoss', use_sigmoid=False, loss_weight=0.5)
+                ]),
+        dict(
+            type='FCNHead',
+            in_channels=256,
+            channels=128,
+            num_convs=1,
+            num_classes=19,
+            in_index=3,
+            norm_cfg=norm_cfg,
+            concat_input=False,
+            align_corners=False,
+            loss_decode=[
+                dict(
+                    type='CrossEntropyLoss',
+                    use_sigmoid=False,
+                    loss_weight=0.1),
+                dict(
+                type='PSLLoss', use_sigmoid=False, loss_weight=0.25)
+                ]),
+    ],
+    # model training and testing settings
+    train_cfg=dict(),
+    test_cfg=dict(mode='whole')
+    )
+
+lr_config = dict(warmup='linear', warmup_iters=1000)
+optimizer = dict(lr=0.01)
+optimizer_config = dict(grad_clip=dict(max_norm=20, norm_type=2))
+data = dict(
+    samples_per_gpu=6,
+    workers_per_gpu=6,
+)
diff --git a/mmseg/models/backbones/__init__.py b/mmseg/models/backbones/__init__.py
index 91a90ebc..caa01c88 100644
--- a/mmseg/models/backbones/__init__.py
+++ b/mmseg/models/backbones/__init__.py
@@ -22,10 +22,12 @@ from .twins import PCPVT, SVT
 from .unet import UNet
 from .vit import VisionTransformer
 
+from .mplseg import MPLSeg
+
 __all__ = [
     'ResNet', 'ResNetV1c', 'ResNetV1d', 'ResNeXt', 'HRNet', 'FastSCNN',
     'ResNeSt', 'MobileNetV2', 'UNet', 'CGNet', 'MobileNetV3',
     'VisionTransformer', 'SwinTransformer', 'MixVisionTransformer',
     'BiSeNetV1', 'BiSeNetV2', 'ICNet', 'TIMMBackbone', 'ERFNet', 'PCPVT',
-    'SVT', 'STDCNet', 'STDCContextPathNet', 'BEiT', 'MAE', 'MSCAN'
+    'SVT', 'STDCNet', 'STDCContextPathNet', 'BEiT', 'MAE', 'MSCAN', 'MPLSeg'
 ]
diff --git a/mmseg/models/backbones/mplseg.py b/mmseg/models/backbones/mplseg.py
new file mode 100644
index 00000000..58550284
--- /dev/null
+++ b/mmseg/models/backbones/mplseg.py
@@ -0,0 +1,148 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+import torch
+import torch.nn as nn
+import torch.nn.functional as F
+from einops import rearrange
+from mmcv.cnn import ConvModule
+from mmcv.runner import BaseModule
+
+from ..builder import BACKBONES, build_backbone
+
+
+class SToD(BaseModule):
+
+    def __init__(self, block_size):
+        super().__init__()
+        self.bs = block_size
+
+    def forward(self, x):
+        x = rearrange(x, 'b c (h h2) (w w2) -> b (h2 w2 c) h w', h2=self.bs, w2=self.bs)
+        return x
+    
+
+class DToS(BaseModule):
+
+    def __init__(self, block_size):
+        super().__init__()
+        self.bs = block_size
+
+    def forward(self, x):
+        x = rearrange(x, 'b (h2 w2 c) h w -> b c (h h2) (w w2)', h2=self.bs, w2=self.bs)
+        return x
+
+
+class Encoder(BaseModule):
+    def __init__(self, backbone_cfg):
+        super(Encoder, self).__init__()
+        self.bb = build_backbone(backbone_cfg)
+
+    def forward(self, x):
+        feat4, feat8, feat16, feat32 = self.bb(x)
+        return feat4, feat8, feat16, feat32
+
+
+class AFM(BaseModule):
+    def __init__(self, in_ch, mid_ch, out_ch, upsample=False, norm_cfg=None):
+        super(AFM, self).__init__()
+    
+        self.mp = nn.Sequential(
+            nn.Conv2d(in_ch, mid_ch//4, 1, padding=0, groups=1, bias=False),
+            nn.InstanceNorm2d(mid_ch//4),
+            nn.Sigmoid(),
+            nn.Conv2d(mid_ch//4, mid_ch//4, 3, padding=1, groups=1, bias=False),
+            nn.InstanceNorm2d(mid_ch//4),
+            nn.Sigmoid(),
+            nn.Conv2d(mid_ch//4, mid_ch, 1, padding=0, groups=1, bias=False),
+            nn.InstanceNorm2d(mid_ch),
+            nn.Sigmoid(),
+        )
+
+        self.pa = nn.Sequential(
+            nn.Conv2d(in_ch, mid_ch//4, 1, padding=0, groups=1, bias=False),
+            nn.InstanceNorm2d(mid_ch//4),
+            nn.Tanh(),
+            nn.Conv2d(mid_ch//4, mid_ch//4, 3, padding=1, groups=1, bias=False),
+            nn.InstanceNorm2d(mid_ch//4),
+            nn.Tanh(),
+            nn.Conv2d(mid_ch//4, mid_ch, 1, padding=0, groups=1, bias=False),
+            nn.InstanceNorm2d(mid_ch),
+            nn.Tanh(),
+        ) 
+
+        self.pw = ConvModule(
+                        in_channels=mid_ch,
+                        out_channels=out_ch,
+                        kernel_size=1,
+                        stride=1,
+                        padding=0,
+                        groups=1,
+                        conv_cfg=None,
+                        norm_cfg=norm_cfg,
+                        act_cfg=dict(type='ReLU'))
+
+        self.eps = 1e-3
+        self.init_weight()
+
+
+    def forward(self, x):
+        fr = torch.fft.rfft2(x, norm='ortho')
+        # fr = torch.fft.fftshift(fr, dim=(2, 3))
+
+        mag = torch.abs(fr)
+        pha = torch.angle(fr+self.eps)
+
+        mag = mag*(1-self.mp(torch.sigmoid(torch.log(mag+self.eps))))
+        pha = pha+self.pa(pha)
+
+        fr = mag * (torch.e**(1j*pha))
+
+        # fr = torch.fft.ifftshift(fr, dim=(2, 3))
+        output = torch.fft.irfft2(fr, norm='ortho')
+        output = F.relu(output, True)
+        output = self.pw(output)
+        return output
+    
+    
+    def init_weight(self):
+        for ly in self.children():
+            if isinstance(ly, nn.Conv2d):
+                nn.init.kaiming_normal_(ly.weight, a=0)
+
+
+@BACKBONES.register_module()
+class MPLSeg(BaseModule):
+
+    def __init__(self,
+                 backbone_cfg,
+                 backbone_channels=(256, 512, 1024, 2048),
+                 mid_channels=(256, 512, 1024, 1024),
+                 fuse_channels=(128, 256, 512, 1024),
+                 out_indices=(0, 1, 2, 3),
+                 norm_cfg=dict(type='BN', requires_grad=True),
+                 init_cfg=None):
+
+        super(MPLSeg, self).__init__(init_cfg=init_cfg)
+
+        self.out_indices = out_indices
+
+        self.enc = Encoder(backbone_cfg)
+        
+        self.up32to16   = AFM(backbone_channels[3],                  mid_channels[3], fuse_channels[3], upsample=True, norm_cfg=norm_cfg)
+        self.up16to8    = AFM(backbone_channels[2]+fuse_channels[3], mid_channels[2], fuse_channels[2], upsample=True, norm_cfg=norm_cfg)
+        self.up8to4     = AFM(backbone_channels[1]+fuse_channels[2], mid_channels[1], fuse_channels[1], upsample=True, norm_cfg=norm_cfg)
+        self.up4tofinal = AFM(backbone_channels[0]+fuse_channels[1], mid_channels[0], fuse_channels[0], upsample=True, norm_cfg=norm_cfg)
+
+    def forward(self, x):
+        feat4, feat8, feat16, feat32= self.cp(x)
+        up32 = self.up32to16(feat32)
+        up32 =  F.interpolate(up32, size=feat16.shape[2:], mode='bilinear', align_corners=False)
+        up16 = self.up16to8(torch.cat([up32, feat16], 1))
+        up16 =  F.interpolate(up16, size=feat8.shape[2:], mode='bilinear', align_corners=False)
+        up8 = self.up8to4(torch.cat([up16, feat8], 1))
+        up8 =  F.interpolate(up8, size=feat4.shape[2:], mode='bilinear', align_corners=False)
+        up4 = self.up4tofinal(torch.cat([up8, feat4], 1))
+
+        outs = [up4, up8, up16, up32]
+        outs = [outs[i] for i in self.out_indices]
+        return tuple(outs)
+
diff --git a/mmseg/models/losses/__init__.py b/mmseg/models/losses/__init__.py
index d7e01974..dfafc634 100644
--- a/mmseg/models/losses/__init__.py
+++ b/mmseg/models/losses/__init__.py
@@ -8,9 +8,11 @@ from .lovasz_loss import LovaszLoss
 from .tversky_loss import TverskyLoss
 from .utils import reduce_loss, weight_reduce_loss, weighted_loss
 
+from .psl_loss import PSLLoss
+
 __all__ = [
     'accuracy', 'Accuracy', 'cross_entropy', 'binary_cross_entropy',
     'mask_cross_entropy', 'CrossEntropyLoss', 'reduce_loss',
     'weight_reduce_loss', 'weighted_loss', 'LovaszLoss', 'DiceLoss',
-    'FocalLoss', 'TverskyLoss'
+    'FocalLoss', 'TverskyLoss', 'PSLLoss'
 ]
diff --git a/mmseg/models/losses/psl_loss.py b/mmseg/models/losses/psl_loss.py
new file mode 100644
index 00000000..33c2713c
--- /dev/null
+++ b/mmseg/models/losses/psl_loss.py
@@ -0,0 +1,78 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+"""Modified from https://github.com/LikeLy-Journey/SegmenTron/blob/master/
+segmentron/solver/loss.py (Apache-2.0 License)"""
+import torch
+import torch.nn as nn
+import torch.nn.functional as F
+
+from ..builder import LOSSES
+from .utils import get_class_weight, weighted_loss
+
+from einops import rearrange, repeat
+
+
+@LOSSES.register_module()
+class PSLLoss(nn.Module):
+
+    def __init__(self,
+                 use_sigmoid=False,
+                 use_mask=False,
+                 reduction='mean',
+                 class_weight=None,
+                 loss_weight=1.0,
+                 loss_name='loss_psl',
+                 avg_non_ignore=False,
+                num_classes=19,
+                
+                 **kwargs):
+        super(PSLLoss, self).__init__()
+        self._loss_name = loss_name
+        self.eps = 1e-5
+        self.n_c = num_classes
+
+    def forward(self,
+                seg_logit,
+                seg_label,
+                weight=None,
+                avg_factor=None,
+                reduction_override=None,
+                ignore_index=255,
+                **kwargs):
+
+        valid_mask = (seg_label != ignore_index).long()
+        seg_logit = seg_logit.softmax(1)
+        seg_label = F.one_hot(
+            torch.clamp(seg_label, 0, self.n_c-1), num_classes=self.n_c).permute(0, 3, 1, 2)
+        
+        seg_label[:,self.n_c-1,:,:] *= valid_mask
+
+        seg_label = torch.fft.rfft2(seg_label, norm='ortho')
+        seg_logit = torch.fft.rfft2(seg_logit, norm='ortho')
+
+        im_label = torch.angle(seg_label+self.eps)
+        im_predict=torch.angle(seg_logit+self.eps)
+
+        re_label = torch.abs(seg_label)
+
+        mask = re_label>1
+
+        im_label = im_label*mask
+        im_predict = im_predict*mask
+        delta = torch.abs(im_label-im_predict)
+        delta = delta.sum()/(mask.sum()+self.eps)
+
+        return delta
+
+    @property
+    def loss_name(self):
+        """Loss Name.
+
+        This function must be implemented and will return the name of this
+        loss function. This name will be used to combine different loss items
+        by simple sum operation. In addition, if you want this loss item to be
+        included into the backward graph, `loss_` must be the prefix of the
+        name.
+        Returns:
+            str: The name of this loss item.
+        """
+        return self._loss_name
-- 
2.47.1.windows.1

